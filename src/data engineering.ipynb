{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import functools as F\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "#from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import Imputer as SimpleImputer\n",
    "from sklearn import metrics   #Additional scklearn functions\n",
    "#from sklearn.grid_search import GridSearchCV #Perforing grid search\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "#Bayesian optimization for model parameters\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bd3fbaa1674dfc4b868ad3b8aaa7b3e3eae37fd3"
   },
   "source": [
    "**Standard Util Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "68bcbad122a503d6877b8fb2c7cd08a2861f33a6"
   },
   "outputs": [],
   "source": [
    "def dataImputation(orig_df):\n",
    "    df = orig_df.copy()\n",
    "    # make new columns indicating what will be imputed\n",
    "    cols_with_missing = (col for col in df.columns if df[col].isnull().any())\n",
    "    #for col in cols_with_missing:\n",
    "    #    df[col + '_was_missing'] = df[col].isnull()\n",
    "    # Imputation\n",
    "    my_imputer = SimpleImputer()\n",
    "    df = pd.DataFrame(my_imputer.fit_transform(df),columns=df.columns.values)\n",
    "    \n",
    "    \n",
    "    print(df.columns)\n",
    "    #print(orig_df.columns)\n",
    "    return df\n",
    "\n",
    "#dataImputation(application_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#Data Input\n",
    "\n",
    "application_train = pd.read_csv('../input/application_train.csv')\n",
    "POS_CASH_balance = pd.read_csv('../input/POS_CASH_balance.csv')\n",
    "bureau_balance = pd.read_csv('../input/bureau_balance.csv')\n",
    "previous_application = pd.read_csv('../input/previous_application.csv')\n",
    "installments_payments = pd.read_csv('../input/installments_payments.csv')\n",
    "credit_card_balance = pd.read_csv('../input/credit_card_balance.csv')\n",
    "bureau = pd.read_csv('../input/bureau.csv')\n",
    "application_test = pd.read_csv('../input/application_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85bc62e2c8b17051f35b0145e7893699d08fc796"
   },
   "source": [
    "**Below Code is finding posterior prob given priro. But Taken count. Next Amount sholud also be used to find posterior mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c0069d195c34cca91be0c2dcb478d4ec5eef6f7"
   },
   "outputs": [],
   "source": [
    "res = pd.merge(application_train,bureau,on=['SK_ID_CURR'],how='inner')\n",
    "count = res.groupby(by = ['CREDIT_TYPE','TARGET']).size().reset_index(name='cnt')\n",
    "#count\n",
    "Total_Population = res.groupby(by = ['TARGET']).size().reset_index(name = 'sample_size')\n",
    "total = Total_Population['sample_size'].sum()\n",
    "Total_Population['t_prop'] = Total_Population['sample_size']/total\n",
    "#\n",
    "Credit_Population = res.groupby(by = ['CREDIT_TYPE']).size().reset_index(name = 'csample_size')\n",
    "Credit_Population['c_prop'] = Credit_Population['csample_size']/total\n",
    "#\n",
    "Credit_Type_Population = count.groupby(by = ['CREDIT_TYPE'])['cnt'].sum().to_dict()\n",
    "count['p_prop'] = count.apply(lambda x,y: x['cnt'] /y[x['CREDIT_TYPE']],args=(Credit_Type_Population,),axis=1 )\n",
    "count[\"prop_p_t\"] = (count['p_prop'] * Total_Population[Total_Population['TARGET']==1]['t_prop'].iloc[0])\n",
    "count = pd.merge(count,Credit_Population,on =['CREDIT_TYPE'],how='left')\n",
    "#Credit_Type_Population['Car loan']\n",
    "count['post_prop'] = count['prop_p_t'] / count['c_prop']\n",
    "count = count[count['TARGET'] ==1]\n",
    "count\n",
    "#Findind post_prop of amt\n",
    "amt_credit = res.groupby(by = ['CREDIT_TYPE','TARGET'])['AMT_CREDIT'].sum().reset_index(name='amt')\n",
    "#count\n",
    "#-- instead of size do sum of amt\n",
    "Total_Population_amt = res.groupby(by = ['TARGET'])['AMT_CREDIT'].sum().reset_index(name = 'sample_size')\n",
    "total_amt = Total_Population_amt['sample_size'].sum()\n",
    "Total_Population_amt['t_prop_amt'] = Total_Population_amt['sample_size']/total_amt\n",
    "#\n",
    "Credit_Population_amt = res.groupby(by = ['CREDIT_TYPE'])['AMT_CREDIT'].sum().reset_index(name = 'csample_size_amt')\n",
    "Credit_Population_amt['c_prop_amt'] = Credit_Population_amt['csample_size_amt']/total_amt\n",
    "#\n",
    "Credit_Type_Population_amt = amt_credit.groupby(by = ['CREDIT_TYPE'])['amt'].sum().to_dict()\n",
    "amt_credit['p_prop_amt'] = amt_credit.apply(lambda x,y: x['amt'] /y[x['CREDIT_TYPE']],args=(Credit_Type_Population_amt,),axis=1 )\n",
    "amt_credit[\"prop_p_t_amt\"] = (amt_credit['p_prop_amt'] * Total_Population_amt[Total_Population_amt['TARGET']==1]['t_prop_amt'].iloc[0])\n",
    "amt_credit = pd.merge(amt_credit,Credit_Population_amt,on =['CREDIT_TYPE'],how='left')\n",
    "#Credit_Type_Population['Car loan']\n",
    "amt_credit['post_prop_amt'] = amt_credit['prop_p_t_amt'] / amt_credit['c_prop_amt']\n",
    "amt_credit = amt_credit[amt_credit['TARGET'] ==1]\n",
    "amt_credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ec7df497d5f546d201271e756ba0ad1cfacd624b"
   },
   "source": [
    "**Application Train Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "478da1b66ddc2e60122f4051ee0b00a552dd44d9"
   },
   "outputs": [],
   "source": [
    "#train_final = dataImputation(application_train)\n",
    "#train_final\n",
    "\n",
    "application_train['NEW_CREDIT_TO_ANNUITY_RATIO'] = application_train['AMT_CREDIT'] / application_train['AMT_ANNUITY']\n",
    "application_train['NEW_CREDIT_TO_GOODS_RATIO'] = application_train['AMT_CREDIT'] / application_train['AMT_GOODS_PRICE']\n",
    "application_train['ANNUITY_TO_INCOME'] = application_train['AMT_ANNUITY'] / application_train['AMT_INCOME_TOTAL']\n",
    "\n",
    "#application_train['NEW_DOC_IND_KURT'] = application_train[docs].kurtosis(axis=1)\n",
    "#application_train['NEW_LIVE_IND_SUM'] = application_train[live].sum(axis=1)\n",
    "\n",
    "# family features\n",
    "application_train['NEW_INC_PER_CHLD'] = application_train['AMT_INCOME_TOTAL'] / (1 + application_train['CNT_CHILDREN'])\n",
    "application_train['NEW_INCOME_PER_PERS'] = application_train['AMT_INCOME_TOTAL'] / application_train['CNT_FAM_MEMBERS']\n",
    "application_train['CHILDREN_RATIO'] = application_train['CNT_CHILDREN'] / application_train['CNT_FAM_MEMBERS']\n",
    "application_train['CNT_NO_CHILD'] = application_train['CNT_FAM_MEMBERS'] - application_train['CNT_CHILDREN']\n",
    "application_train['CREDIT_PER_PERS'] = application_train['AMT_CREDIT'] / application_train['CNT_FAM_MEMBERS']\n",
    "application_train['CREDIT_PER_CHILD'] = application_train['AMT_CREDIT'] / (1 + application_train['CNT_CHILDREN'])\n",
    "application_train['CREDIT_PER_NO_CHILD'] = application_train['AMT_CREDIT'] / application_train['CNT_NO_CHILD']\n",
    "\n",
    "# extract most features from external sources\n",
    "application_train['NEW_SOURCES_PROD'] = application_train['EXT_SOURCE_1'] * application_train['EXT_SOURCE_2'] * application_train['EXT_SOURCE_3']\n",
    "application_train['NEW_EXT_SOURCES_MEAN'] = application_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "application_train['NEW_SCORES_STD'] = application_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
    "application_train['NEW_SCORES_STD'] = application_train['NEW_SCORES_STD'].fillna(application_train['NEW_SCORES_STD'].mean())\n",
    "\n",
    "application_train['NEW_CAR_TO_BIRTH_RATIO'] = application_train['OWN_CAR_AGE'] / application_train['DAYS_BIRTH']\n",
    "application_train['NEW_CAR_TO_EMPLOY_RATIO'] = application_train['OWN_CAR_AGE'] / application_train['DAYS_EMPLOYED']\n",
    "application_train['NEW_PHONE_TO_BIRTH_RATIO'] = application_train['DAYS_LAST_PHONE_CHANGE'] / application_train['DAYS_BIRTH']\n",
    "application_train['NEW_PHONE_TO_BIRTH_RATIO_EMPLOYER'] = application_train['DAYS_LAST_PHONE_CHANGE'] / application_train['DAYS_EMPLOYED']\n",
    "application_train['NEW_CREDIT_TO_INCOME_RATIO'] = application_train['AMT_CREDIT'] / application_train['AMT_INCOME_TOTAL']\n",
    "#New Features\n",
    "application_train['INCOME_BY_DAYS_EMP'] = application_train['AMT_INCOME_TOTAL']/(1+application_train['DAYS_EMPLOYED'])\n",
    "application_train['LOW_OCC'] = map(lambda x: 1 if x.isin(['Cooking staff','Drivers','Laborers','Low-skill Laborers','Security staff','Waiters/barmen staff']) else 0,application_train['OCCUPATION_TYPE'])\n",
    "application_train['AVG_EXT_SOURCE'] = (application_train['EXT_SOURCE_1'] + 2*application_train['EXT_SOURCE_2'] + 3*application_train['EXT_SOURCE_3']) / 3\n",
    "# Below features to test Feature importance\n",
    "application_train['DAYS_EMP_TO_BIRTH_RATIO'] = (application_train['DAYS_EMPLOYED']/application_train['DAYS_BIRTH'])\n",
    "application_train['AMT_ANNUITY_TO_DAYS_EMP_RATIO'] = application_train['AMT_ANNUITY'] / application_train['DAYS_EMPLOYED']\n",
    "application_train['AMT_ANNUITY_TO_DAYS_BIRTH_RATIO'] = application_train['AMT_ANNUITY'] / application_train['DAYS_BIRTH']\n",
    "\n",
    "application_train['AMT_INC_TO_DAYS_BIRTH_RATIO'] = application_train['AMT_INCOME_TOTAL'] / application_train['DAYS_BIRTH']\n",
    "application_train['AMT_GOODS_PER_PERS'] = application_train['AMT_GOODS_PRICE'] / application_train['CNT_FAM_MEMBERS']\n",
    "application_train['AMT_ANNUITY_PER_PERS'] = application_train['AMT_ANNUITY'] / application_train['CNT_FAM_MEMBERS']\n",
    "application_train['INCOME_BY_AVG_EXT_SOURCE'] = application_train['AMT_INCOME_TOTAL']/(1+application_train['AVG_EXT_SOURCE'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1681e74146a5401e1de9b93bde2a6a0a1273394c"
   },
   "source": [
    "**Application Test Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ce9456fb5a1b898ee2646ff149dbedc8273275e2"
   },
   "outputs": [],
   "source": [
    "#train_final = dataImputation(application_test)\n",
    "#train_final\n",
    "\n",
    "application_test['NEW_CREDIT_TO_ANNUITY_RATIO'] = application_test['AMT_CREDIT'] / application_test['AMT_ANNUITY']\n",
    "application_test['NEW_CREDIT_TO_GOODS_RATIO'] = application_test['AMT_CREDIT'] / application_test['AMT_GOODS_PRICE']\n",
    "application_test['ANNUITY_TO_INCOME'] = application_test['AMT_ANNUITY'] / application_test['AMT_INCOME_TOTAL']\n",
    "\n",
    "#application_test['NEW_DOC_IND_KURT'] = application_test[docs].kurtosis(axis=1)\n",
    "#application_test['NEW_LIVE_IND_SUM'] = application_test[live].sum(axis=1)\n",
    "\n",
    "# family features\n",
    "application_test['NEW_INC_PER_CHLD'] = application_test['AMT_INCOME_TOTAL'] / (1 + application_test['CNT_CHILDREN'])\n",
    "application_test['NEW_INCOME_PER_PERS'] = application_test['AMT_INCOME_TOTAL'] / application_test['CNT_FAM_MEMBERS']\n",
    "application_test['CHILDREN_RATIO'] = application_test['CNT_CHILDREN'] / application_test['CNT_FAM_MEMBERS']\n",
    "application_test['CNT_NO_CHILD'] = application_test['CNT_FAM_MEMBERS'] - application_test['CNT_CHILDREN']\n",
    "application_test['CREDIT_PER_PERS'] = application_test['AMT_CREDIT'] / application_test['CNT_FAM_MEMBERS']\n",
    "application_test['CREDIT_PER_CHILD'] = application_test['AMT_CREDIT'] / (1 + application_test['CNT_CHILDREN'])\n",
    "application_test['CREDIT_PER_NO_CHILD'] = application_test['AMT_CREDIT'] / application_test['CNT_NO_CHILD']\n",
    "\n",
    "# extract most features from external sources\n",
    "application_test['NEW_SOURCES_PROD'] = application_test['EXT_SOURCE_1'] * application_test['EXT_SOURCE_2'] * application_test['EXT_SOURCE_3']\n",
    "application_test['NEW_EXT_SOURCES_MEAN'] = application_test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "application_test['NEW_SCORES_STD'] = application_test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
    "application_test['NEW_SCORES_STD'] = application_test['NEW_SCORES_STD'].fillna(application_test['NEW_SCORES_STD'].mean())\n",
    "\n",
    "application_test['NEW_CAR_TO_BIRTH_RATIO'] = application_test['OWN_CAR_AGE'] / application_test['DAYS_BIRTH']\n",
    "application_test['NEW_CAR_TO_EMPLOY_RATIO'] = application_test['OWN_CAR_AGE'] / application_test['DAYS_EMPLOYED']\n",
    "application_test['NEW_PHONE_TO_BIRTH_RATIO'] = application_test['DAYS_LAST_PHONE_CHANGE'] / application_test['DAYS_BIRTH']\n",
    "application_test['NEW_PHONE_TO_BIRTH_RATIO_EMPLOYER'] = application_test['DAYS_LAST_PHONE_CHANGE'] / application_test['DAYS_EMPLOYED']\n",
    "application_test['NEW_CREDIT_TO_INCOME_RATIO'] = application_test['AMT_CREDIT'] / application_test['AMT_INCOME_TOTAL']\n",
    "# New Features\n",
    "application_test['INCOME_BY_DAYS_EMP'] = application_test['AMT_INCOME_TOTAL']/(1+application_test['DAYS_EMPLOYED'])\n",
    "application_test['LOW_OCC'] = map(lambda x: 1 if x.isin(['Cooking staff','Drivers','Laborers','Low-skill Laborers','Security staff','Waiters/barmen staff']) else 0,application_test['OCCUPATION_TYPE'])\n",
    "application_test['AVG_EXT_SOURCE'] =(application_test['EXT_SOURCE_1'] + 2*application_test['EXT_SOURCE_2'] + 3*application_test['EXT_SOURCE_3']) / 3\n",
    "# Below features to test Feature importance\n",
    "application_test['DAYS_EMP_TO_BIRTH_RATIO'] = (application_test['DAYS_EMPLOYED']/application_test['DAYS_BIRTH'])\n",
    "application_test['AMT_ANNUITY_TO_DAYS_EMP_RATIO'] = application_test['AMT_ANNUITY'] / application_test['DAYS_EMPLOYED']\n",
    "application_test['AMT_ANNUITY_TO_DAYS_BIRTH_RATIO'] = application_test['AMT_ANNUITY'] / application_test['DAYS_BIRTH']\n",
    "\n",
    "application_test['AMT_INC_TO_DAYS_BIRTH_RATIO'] = application_test['AMT_INCOME_TOTAL'] / application_test['DAYS_BIRTH']\n",
    "application_test['AMT_GOODS_PER_PERS'] = application_test['AMT_GOODS_PRICE'] / application_test['CNT_FAM_MEMBERS']\n",
    "application_test['AMT_ANNUITY_PER_PERS'] = application_test['AMT_ANNUITY'] / application_test['CNT_FAM_MEMBERS']\n",
    "application_test['INCOME_BY_AVG_EXT_SOURCE'] = application_test['AMT_INCOME_TOTAL']/(1+application_test['AVG_EXT_SOURCE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "095d893b8501d7d913d98cdedc99c71075b45cbd"
   },
   "source": [
    "**BUREAU BASED FEATURES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5dcb95e768eafcde5f6abae22cee05c90a4161be",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BUREAU_FEATURES=bureau[['SK_ID_CURR']].drop_duplicates()\n",
    "#FEATURE 1 - NUMBER OF PAST LOANS PER CUSTOMER\n",
    "BUREAU_LOAN_COUNT = bureau[['SK_ID_CURR','CREDIT_TYPE']].groupby(by=['SK_ID_CURR'])['CREDIT_TYPE'].count().reset_index(name='BUREAU_LOAN_COUNT')\n",
    "BUREAU_FEATURES = BUREAU_FEATURES.merge(BUREAU_LOAN_COUNT,on=['SK_ID_CURR'],how='left')\n",
    "\n",
    "#FEATURE 2 - NUMBER OF TYPES OF PAST LOANS PER CUSTOMER\n",
    "BUREAU_LOAN_TYPES = bureau[['SK_ID_CURR', 'CREDIT_TYPE']].groupby(by = ['SK_ID_CURR'])['CREDIT_TYPE'].nunique().reset_index().rename(index=str, columns={'CREDIT_TYPE': 'BUREAU_LOAN_TYPES'})\n",
    "BUREAU_FEATURES = BUREAU_FEATURES.merge(BUREAU_LOAN_TYPES,on=['SK_ID_CURR'],how='left')\n",
    "\n",
    "#Feature 3 - Net Sum of Posterior Probabilites\n",
    "BUREAU_NET_SUM_POST_PROP = pd.merge(bureau[['SK_ID_CURR', 'CREDIT_TYPE']],count[['CREDIT_TYPE','post_prop']] ,on=['CREDIT_TYPE'],how='left' ).groupby(by = ['SK_ID_CURR'])['post_prop'].sum().reset_index(name='BUREAU_NET_SUM_POST_PROP')\n",
    "BUREAU_FEATURES = BUREAU_FEATURES.merge(BUREAU_NET_SUM_POST_PROP,on=['SK_ID_CURR'],how='left')\n",
    "\n",
    "#Feature 4 - Net Product of Posterior Probabilites\n",
    "BUREAU_NET_PROD_POST_PROP = pd.merge(bureau[['SK_ID_CURR', 'CREDIT_TYPE']],count[['CREDIT_TYPE','post_prop']] ,on=['CREDIT_TYPE'],how='left' ).groupby(by = ['SK_ID_CURR'])['post_prop'].prod().reset_index(name='BUREAU_NET_PROD_POST_PROP')\n",
    "BUREAU_FEATURES = BUREAU_FEATURES.merge(BUREAU_NET_PROD_POST_PROP,on=['SK_ID_CURR'],how='left')\n",
    "\n",
    "#Feature 5 - Net Sum of AMT Posterior Probabilites\n",
    "BUREAU_NET_SUM_AMT_POST_PROP = pd.merge(bureau[['SK_ID_CURR', 'CREDIT_TYPE']],amt_credit[['CREDIT_TYPE','post_prop_amt']] ,on=['CREDIT_TYPE'],how='left' ).groupby(by = ['SK_ID_CURR'])['post_prop_amt'].sum().reset_index(name='BUREAU_NET_SUM_AMT_POST_PROP')\n",
    "BUREAU_FEATURES = BUREAU_FEATURES.merge(BUREAU_NET_SUM_AMT_POST_PROP,on=['SK_ID_CURR'],how='left')\n",
    "\n",
    "#Feature 6 - Net Product of AMT Posterior Probabilites\n",
    "BUREAU_NET_PROD_AMT_POST_PROP = pd.merge(bureau[['SK_ID_CURR', 'CREDIT_TYPE']],amt_credit[['CREDIT_TYPE','post_prop_amt']] ,on=['CREDIT_TYPE'],how='left' ).groupby(by = ['SK_ID_CURR'])['post_prop_amt'].prod().reset_index(name='BUREAU_NET_PROD_AMT_POST_PROP')\n",
    "BUREAU_FEATURES = BUREAU_FEATURES.merge(BUREAU_NET_PROD_AMT_POST_PROP,on=['SK_ID_CURR'],how='left')\n",
    "\n",
    "#Ratio BUREAU_LOAN_TYPES/BUREAU_LOAN_COUNT\n",
    "    #Is the Customer diversified in taking multiple types of Loan or Focused on a single type of loan\n",
    "BUREAU_FEATURES['BUREAU_LOAN_PER_TYPE'] = BUREAU_FEATURES['BUREAU_LOAN_COUNT'] / BUREAU_FEATURES['BUREAU_LOAN_TYPES']\n",
    "#BUREAU_FEATURES\n",
    "\n",
    "DAY_CREDIT_DIFF=bureau[['SK_ID_CURR', 'SK_ID_BUREAU', 'DAYS_CREDIT']].groupby(by = ['SK_ID_CURR']).apply(lambda x: x.sort_values(['DAYS_CREDIT'], ascending = False)).reset_index(drop = True)\n",
    "DAY_CREDIT_DIFF['DAYS_CREDIT1'] = DAY_CREDIT_DIFF['DAYS_CREDIT']*-1\n",
    "DAY_CREDIT_DIFF['DAYS_DIFF'] = DAY_CREDIT_DIFF.groupby(by = ['SK_ID_CURR'])['DAYS_CREDIT1'].diff().fillna(0)\n",
    "# Now find Mean of above DAY_CREDIT_DIFF\n",
    "DAYS_DIFF_MEAN = DAY_CREDIT_DIFF.groupby(by = ['SK_ID_CURR'])['DAYS_DIFF'].mean().reset_index(name='DAYS_DIFF_MEAN').fillna(0)\n",
    "# Now find standarad deviation of above DAY_CREDIT_DIFF\n",
    "DAYS_DIFF_STD = DAY_CREDIT_DIFF.groupby(by=['SK_ID_CURR'])['DAYS_DIFF'].std().reset_index(name='DAYS_DIFF_STD').fillna(1)\n",
    "#DAYS_DIFF_RATIO = DAY_CREDIT_DIFF['DAYS_DIFF_MEAN']/DAY_CREDIT_DIFF['DAYS_DIFF_STD']\n",
    "DAYS_DIFF_JOIN = DAYS_DIFF_MEAN.merge(DAYS_DIFF_STD,on='SK_ID_CURR',how='inner')\n",
    "DAYS_DIFF_JOIN['DAYS_DIFF_RATIO'] = DAYS_DIFF_JOIN['DAYS_DIFF_MEAN']/DAYS_DIFF_JOIN['DAYS_DIFF_STD']\n",
    "#DAYS_DIFF_JOIN\n",
    "#DAY_CREDIT_DIFF\n",
    "\n",
    "BUREAU_FEATURES = BUREAU_FEATURES.merge(DAYS_DIFF_JOIN,on='SK_ID_CURR',how='left')\n",
    "bureau['BUREAU_DAY_CREDIT_BY_CNT_PROLONG']=(bureau['DAYS_CREDIT'] *-1)/(bureau['CNT_CREDIT_PROLONG']+1)\n",
    "BUREAU_CNT_PROLONG_FEATURES = bureau[bureau['CREDIT_ACTIVE']==\"Active\"].groupby(by = ['SK_ID_CURR'])[\n",
    "    'BUREAU_DAY_CREDIT_BY_CNT_PROLONG' ,\n",
    "    'CNT_CREDIT_PROLONG'\n",
    "].agg(['min','max','sum','mean','var','count','std']).reset_index()\n",
    "\n",
    "BUREAU_CNT_PROLONG_FEATURES.columns = ['_'.join(col).strip('_') for col in BUREAU_CNT_PROLONG_FEATURES.columns.values]\n",
    "BUREAU_FEATURES = BUREAU_FEATURES.merge(BUREAU_CNT_PROLONG_FEATURES,on='SK_ID_CURR',how='left')\n",
    "\n",
    "#bureau.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f52315e7014204c12d8a09e8ba92e55c2fe467a9"
   },
   "outputs": [],
   "source": [
    "# Credit card data - numerical features\n",
    "wm = lambda x: np.average(x, weights=-1/credit_card_balance.loc[x.index, 'MONTHS_BALANCE'])\n",
    "credit_card_avgs = credit_card_balance.groupby('SK_ID_CURR').agg(wm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "61ee7cf244ad9c541598028fbbae584ff4385f93"
   },
   "source": [
    "**Previous_application Past Application in HomeCredit (Current Application ID x Past Application ID)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "83279be1198f3c4bb50c3eb7d71e18f560f7c4c2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Percentage of  Past Applied Credit Rejected\n",
    "#previous_application['PCT_PAST_REJECT']= previous_application[['SK_ID_CURR','NAME_CONTRACT_STATUS']].groupby(by=['SK_ID_CURR']).agg(np.sum(np.where(previous_application[['NAME_CONTRACT_STATUS']]==\"Refused\")).astype('float'))\n",
    "PREV_APP_FEATURES = previous_application['SK_ID_CURR'].drop_duplicates()\n",
    "\n",
    "#Feature Previous Refused application AMT_CREDIT/AMT_APPLICATION\n",
    "PREV_REFUSED_RATIO_CREDIT_APPLICATION = previous_application[(previous_application['NAME_CONTRACT_STATUS'] == 'Refused') ].groupby(by=['SK_ID_CURR']).apply(lambda x: x['AMT_CREDIT'].sum()/x['AMT_APPLICATION'].sum()).reset_index(name='PREV_REFUSED_RATIO_CREDIT_APPLICATION')\n",
    "\n",
    "#Feature Previous Refused application AMT_CREDIT/AMT_APPLICATION\n",
    "PREV_NOT_REFUSED_RATIO_CREDIT_APPLICATION = previous_application[(previous_application['NAME_CONTRACT_STATUS'] != 'Refused') ].groupby(by=['SK_ID_CURR']).apply(lambda x: x['AMT_CREDIT'].sum()/x['AMT_APPLICATION'].sum()).reset_index(name='PREV_NOT_REFUSED_RATIO_CREDIT_APPLICATION')\n",
    "\n",
    "#Feature Previous Refused application AMT_ANNUITY/AMT_APPLICATION\n",
    "PREV_REFUSED_RATIO_ANNUITY_APPLICATION = previous_application[(previous_application['NAME_CONTRACT_STATUS'] == 'Refused') ].groupby(by=['SK_ID_CURR']).apply(lambda x: x['AMT_ANNUITY'].sum()/x['AMT_APPLICATION'].sum()).reset_index(name='PREV_REFUSED_RATIO_ANNUITY_APPLICATION')\n",
    "\n",
    "#Feature Previous Not Refused application AMT_ANNUITY/AMT_APPLICATION\n",
    "PREV_NOT_REFUSED_RATIO_ANNUITY_APPLICATION = previous_application[(previous_application['NAME_CONTRACT_STATUS'] != 'Refused') ].groupby(by=['SK_ID_CURR']).apply(lambda x: x['AMT_ANNUITY'].sum()/x['AMT_APPLICATION'].sum()).reset_index(name='PREV_NOT_REFUSED_RATIO_ANNUITY_APPLICATION')\n",
    "\n",
    "PREV_NFLAG_INSURED_SUM = previous_application.groupby(['SK_ID_CURR'])['NFLAG_INSURED_ON_APPROVAL'].sum().reset_index(name='PREV_NFLAG_INSURED_SUM')\n",
    "\n",
    "# Feature Previous Refused application AMT_GOODS_PRICE/AMT_CREDIT\n",
    "PREV_NOT_REFUSED_RATIO_AMT_GOODS_PRICE_CREDIT = previous_application[(previous_application['NAME_CONTRACT_STATUS'] != 'Refused') ].groupby(by=['SK_ID_CURR']).apply(lambda x: x['AMT_GOODS_PRICE'].sum()/x['AMT_CREDIT'].sum()).reset_index(name='PREV_NOT_REFUSED_RATIO_AMT_GOODS_PRICE_CREDIT')\n",
    "\n",
    "# Feature Previous Refused application AMT_GOODS_PRICE/AMT_CREDIT\n",
    "PREV_REFUSED_RATIO_AMT_GOODS_PRICE_CREDIT = previous_application[(previous_application['NAME_CONTRACT_STATUS'] == 'Refused') ].groupby(by=['SK_ID_CURR']).apply(lambda x: x['AMT_GOODS_PRICE'].sum()/x['AMT_CREDIT'].sum()).reset_index(name='PREV_REFUSED_RATIO_AMT_GOODS_PRICE_CREDIT')\n",
    "\n",
    "#Feature Previous NOT Refused application AMT_GOODS_PRICE/AMT_ANNUITY\n",
    "PREV_NOT_REFUSED_RATIO_GOODS_ANNUITY = previous_application[(previous_application['NAME_CONTRACT_STATUS'] != 'Refused') ].groupby(by=['SK_ID_CURR']).apply(lambda x: x['AMT_GOODS_PRICE'].sum()/x['AMT_ANNUITY'].sum()).reset_index(name='PREV_NOT_REFUSED_RATIO_GOODS_ANNUITY')\n",
    "\n",
    "#Feature Previous Refused application AMT_GOODS_PRICE/AMT_ANNUITY\n",
    "PREV_REFUSED_RATIO_GOODS_ANNUITY = previous_application[(previous_application['NAME_CONTRACT_STATUS'] == 'Refused') ].groupby(by=['SK_ID_CURR']).apply(lambda x: x['AMT_GOODS_PRICE'].sum()/x['AMT_ANNUITY'].sum()).reset_index(name='PREV_REFUSED_RATIO_GOODS_ANNUITY')\n",
    "\n",
    "# Feature NAME_PAYMENT_TYPE = 'Cash through the bank'. Find Ratio AMT_GOODS_PRICE/AMT_ANNUITY\n",
    "\n",
    "#NFLAG_INSURED_ON_APPROVAL\n",
    "#NFLAG_MICRO_CASH\n",
    "\n",
    "'''\n",
    "These Features are yet to be developed\n",
    "    PREV_REJECTED_TOTAL_DEBT_TO_INCOME_RATIO\n",
    "    PREV_REJECTED_AMT_CREDIT_TO_INCOME_RATIO\n",
    "'''\n",
    "previous_application['PREV_CASH_TOTAL_DEBT_TO_AMT_CREDIT'] = (previous_application[previous_application['NAME_CONTRACT_TYPE'] =='Cash loans']['AMT_ANNUITY'] * previous_application[previous_application['NAME_CONTRACT_TYPE'] =='Cash loans']['CNT_PAYMENT']) / previous_application[previous_application['NAME_CONTRACT_TYPE'] =='Cash loans']['AMT_CREDIT']\n",
    "\n",
    "previous_application['PREV_NON_CASH_TOTAL_DEBT_TO_AMT_CREDIT'] = (previous_application[previous_application['NAME_CONTRACT_TYPE'] !='Cash loans']['AMT_ANNUITY'] * previous_application[previous_application['NAME_CONTRACT_TYPE'] !='Cash loans']['CNT_PAYMENT']) / previous_application[previous_application['NAME_CONTRACT_TYPE'] !='Cash loans']['AMT_CREDIT']\n",
    "\n",
    "previous_application_features = previous_application.groupby(by = ['SK_ID_CURR'])['PREV_NON_CASH_TOTAL_DEBT_TO_AMT_CREDIT',\n",
    "                   'PREV_CASH_TOTAL_DEBT_TO_AMT_CREDIT',\n",
    "                   'DAYS_DECISION'\n",
    "                   ].agg(['min','max','sum','mean','var','count','std']).reset_index()\n",
    "   \n",
    "previous_application_features.columns = ['_'.join(col).strip('_') for col in previous_application_features.columns.values]\n",
    "previous_application_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "347be3b31a84ad880edac3687c369fc931873831"
   },
   "source": [
    "**Installment Based Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30a6c12921ceac2d4821d602538fccf93200df16",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# aggs = ['min','max','sum','mean','var','count']\n",
    "# ip = installments_payments.groupby(by = ['SK_ID_CURR','SK_ID_PREV'])['NUM_INSTALMENT_NUMBER'].agg(['count','max']).reset_index()\n",
    "# ip.where((ip['max']-ip['count']) > 0)\n",
    "\n",
    "#ip[(ip['max']-ip['count']) > 0]\n",
    "#application_train[application_train['SK_ID_CURR']==100033]\n",
    "#application_train[application_train['TARGET']==1].count()\n",
    "#installments_payments[installments_payments['SK_ID_PREV']==2037234]\n",
    "def day_distribution(x):\n",
    "    from math import exp\n",
    "    if (x['DAYS_INSTALMENT_DAYS_ENTRY_PAYMENT_DIFF']>=1):\n",
    "        return x['AMT_PAYMENT'] * exp(-abs(float(x['DAYS_INSTALMENT_DAYS_ENTRY_PAYMENT_DIFF']))/20)\n",
    "    else :\n",
    "        return x['AMT_PAYMENT']\n",
    "        \n",
    "installments_payments['DAYS_INSTALMENT_DAYS_ENTRY_PAYMENT_DIFF'] = installments_payments['DAYS_INSTALMENT']-installments_payments['DAYS_ENTRY_PAYMENT']\n",
    "installments_payments['AMT_INSTALMENT_AMT_PAYMENT_DIFF'] = installments_payments['AMT_INSTALMENT'] -installments_payments['AMT_PAYMENT']\n",
    "installments_payments['AMT_PAYMENT_DECAY']  = installments_payments[['DAYS_INSTALMENT_DAYS_ENTRY_PAYMENT_DIFF','AMT_PAYMENT']].apply(day_distribution,axis = 1)\n",
    "installments_payments['AMT_INSTALMENT_AMT_PAYMENT_DECAY_DIFF'] = installments_payments['AMT_INSTALMENT'] -installments_payments['AMT_PAYMENT_DECAY']\n",
    "'''\n",
    "    Also find number of miss installments\n",
    "    Sum of Total Instalments per SK_ID_CURR,SK_ID_PREV\n",
    "'''\n",
    "installments_payments_features = installments_payments.groupby(by = ['SK_ID_CURR'])['AMT_INSTALMENT',\n",
    "                   'AMT_PAYMENT',\n",
    "                   'AMT_INSTALMENT_AMT_PAYMENT_DECAY_DIFF',\n",
    "                   'AMT_PAYMENT_DECAY',\n",
    "                   'DAYS_ENTRY_PAYMENT',\n",
    "                   'DAYS_INSTALMENT',\n",
    "                   'NUM_INSTALMENT_NUMBER',\n",
    "                   'NUM_INSTALMENT_VERSION',\n",
    "                   'DAYS_INSTALMENT_DAYS_ENTRY_PAYMENT_DIFF',\n",
    "                   'AMT_INSTALMENT_AMT_PAYMENT_DIFF'\n",
    "                   ].agg(['min','max','sum','mean','var','count','std']).reset_index()\n",
    "installments_payments_features.columns = ['_'.join(col).strip('_') for col in installments_payments_features.columns.values]\n",
    "installments_payments_features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e2e6a643cede4da92293fd6e51d01f6e68bbdb17",
    "collapsed": true
   },
   "source": [
    "**Finally Joining All the Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f3c293d005d46be8c90dce93bc99ce96ed7b740"
   },
   "outputs": [],
   "source": [
    "Join_DF_LIST = [application_train,BUREAU_FEATURES,PREV_REFUSED_RATIO_CREDIT_APPLICATION,PREV_NOT_REFUSED_RATIO_CREDIT_APPLICATION,PREV_REFUSED_RATIO_ANNUITY_APPLICATION,PREV_NOT_REFUSED_RATIO_ANNUITY_APPLICATION,PREV_NFLAG_INSURED_SUM,PREV_NOT_REFUSED_RATIO_AMT_GOODS_PRICE_CREDIT,PREV_REFUSED_RATIO_AMT_GOODS_PRICE_CREDIT,PREV_NOT_REFUSED_RATIO_GOODS_ANNUITY,PREV_REFUSED_RATIO_GOODS_ANNUITY,installments_payments_features,previous_application_features]\n",
    "application_train = F.reduce(lambda left,right:pd.merge(left,right,on='SK_ID_CURR',how='left'), Join_DF_LIST)\n",
    "\n",
    "\n",
    "Test_Join_DF_LIST = [application_test,BUREAU_FEATURES,PREV_REFUSED_RATIO_CREDIT_APPLICATION,PREV_NOT_REFUSED_RATIO_CREDIT_APPLICATION,PREV_REFUSED_RATIO_ANNUITY_APPLICATION,PREV_NOT_REFUSED_RATIO_ANNUITY_APPLICATION,PREV_NFLAG_INSURED_SUM,PREV_NOT_REFUSED_RATIO_AMT_GOODS_PRICE_CREDIT,PREV_REFUSED_RATIO_AMT_GOODS_PRICE_CREDIT,PREV_NOT_REFUSED_RATIO_GOODS_ANNUITY,PREV_REFUSED_RATIO_GOODS_ANNUITY,installments_payments_features,previous_application_features]\n",
    "application_test = F.reduce(lambda left,right:pd.merge(left,right,on='SK_ID_CURR',how='left'), Test_Join_DF_LIST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "48334f778e649de606da783d3c339807531b710f"
   },
   "source": [
    "**Preprocessing Train Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c8b4fcf0f7adad68ec81a77e23633fdf8e355311",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#previous_application.columns.values\n",
    "#pd.merge(application_train,previous_application,on=\"SK_ID_CURR\")\n",
    "#previous_application[previous_application[\"SK_ID_CURR\"] == 100002]\n",
    "#bureau\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_at= LabelEncoder()\n",
    "application_train_colummns = application_train.select_dtypes(include= ['object']).columns.values\n",
    "application_train[application_train_colummns] = application_train[application_train_colummns].astype(str).apply(le_at.fit_transform)\n",
    "\n",
    "#Filling NAN's for float with mean \n",
    "#application_train.head(10)\n",
    "application_train_float_columns =application_train.select_dtypes(include= ['float64']).columns.values\n",
    "application_train[application_train_float_columns]=application_train[application_train_float_columns].fillna(application_train[application_train_float_columns].mean())\n",
    "\n",
    "application_train = application_train.replace([np.inf, -np.inf], 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e8f4b44ebafe94b679b6bbcd0dce5bd42dcb1fee"
   },
   "source": [
    "**Preprocessing Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8a494b07b6b92ab5c2b2a8f88a7a28d1d9015b2b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "application_test_colummns = application_test.select_dtypes(include= ['object']).columns.values\n",
    "application_test[application_test_colummns] = application_test[application_test_colummns].astype(str).apply(le_at.fit_transform)\n",
    "\n",
    "#Filling NAN's for float with mean \n",
    "#application_test.head(10)\n",
    "application_test_float_columns =application_test.select_dtypes(include= ['float64']).columns.values\n",
    "application_test[application_test_float_columns]=application_test[application_test_float_columns].fillna(application_test[application_test_float_columns].mean())\n",
    "\n",
    "application_test = application_test.replace([np.inf, -np.inf], 0)\n",
    "test_final = dataImputation(application_test)\n",
    "\n",
    "target=\"TARGET\"\n",
    "#Imputing Values using sklearn imputer\n",
    "train_final = dataImputation(application_train)\n",
    "#predictors = [x for x in train_final.columns.values if x not in [target,'SK_ID_CURR']]\n",
    "'''Below Feature are selected from Feature selection module, \n",
    "if want to train on whole set of features then uncomment 1st line'''\n",
    "#predictors = [x for x in train_final.columns.values if x not in [target,'SK_ID_CURR']]\n",
    "predictors = ['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OWN_CAR_AGE', 'OCCUPATION_TYPE', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'LIVINGAREA_AVG', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BEGINEXPLUATATION_MEDI', 'TOTALAREA_MODE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_3', 'NEW_CREDIT_TO_ANNUITY_RATIO', 'NEW_CREDIT_TO_GOODS_RATIO', 'ANNUITY_TO_INCOME', 'CREDIT_PER_PERS', 'CREDIT_PER_CHILD', 'CREDIT_PER_NO_CHILD', 'NEW_SOURCES_PROD', 'NEW_EXT_SOURCES_MEAN', 'NEW_SCORES_STD', 'NEW_CAR_TO_BIRTH_RATIO', 'NEW_CAR_TO_EMPLOY_RATIO', 'NEW_PHONE_TO_BIRTH_RATIO', 'NEW_PHONE_TO_BIRTH_RATIO_EMPLOYER', 'NEW_CREDIT_TO_INCOME_RATIO', 'INCOME_BY_DAYS_EMP', 'AVG_EXT_SOURCE', 'DAYS_EMP_TO_BIRTH_RATIO', 'AMT_ANNUITY_TO_DAYS_EMP_RATIO', 'AMT_ANNUITY_TO_DAYS_BIRTH_RATIO', 'AMT_INC_TO_DAYS_BIRTH_RATIO', 'AMT_GOODS_PER_PERS', 'AMT_ANNUITY_PER_PERS', 'BUREAU_NET_SUM_POST_PROP', 'BUREAU_NET_PROD_POST_PROP', 'BUREAU_NET_SUM_AMT_POST_PROP', 'BUREAU_NET_PROD_AMT_POST_PROP', 'DAYS_DIFF_MEAN', 'BUREAU_DAY_CREDIT_BY_CNT_PROLONG_min', 'BUREAU_DAY_CREDIT_BY_CNT_PROLONG_max', 'BUREAU_DAY_CREDIT_BY_CNT_PROLONG_mean', 'BUREAU_DAY_CREDIT_BY_CNT_PROLONG_count', 'CNT_CREDIT_PROLONG_count', 'PREV_REFUSED_RATIO_CREDIT_APPLICATION', 'PREV_NOT_REFUSED_RATIO_CREDIT_APPLICATION', 'PREV_REFUSED_RATIO_ANNUITY_APPLICATION', 'PREV_NOT_REFUSED_RATIO_ANNUITY_APPLICATION', 'PREV_NOT_REFUSED_RATIO_AMT_GOODS_PRICE_CREDIT', 'PREV_REFUSED_RATIO_AMT_GOODS_PRICE_CREDIT', 'PREV_NOT_REFUSED_RATIO_GOODS_ANNUITY', 'PREV_REFUSED_RATIO_GOODS_ANNUITY', 'AMT_INSTALMENT_min', 'AMT_INSTALMENT_max', 'AMT_INSTALMENT_sum', 'AMT_INSTALMENT_mean', 'AMT_PAYMENT_min', 'AMT_PAYMENT_max', 'AMT_PAYMENT_sum', 'AMT_PAYMENT_mean', 'AMT_INSTALMENT_AMT_PAYMENT_DECAY_DIFF_min', 'AMT_INSTALMENT_AMT_PAYMENT_DECAY_DIFF_max', 'AMT_INSTALMENT_AMT_PAYMENT_DECAY_DIFF_sum', 'AMT_INSTALMENT_AMT_PAYMENT_DECAY_DIFF_mean', 'AMT_PAYMENT_DECAY_min', 'AMT_PAYMENT_DECAY_sum', 'DAYS_ENTRY_PAYMENT_min', 'DAYS_ENTRY_PAYMENT_max', 'DAYS_ENTRY_PAYMENT_sum', 'DAYS_ENTRY_PAYMENT_mean', 'DAYS_ENTRY_PAYMENT_var', 'DAYS_ENTRY_PAYMENT_std', 'DAYS_INSTALMENT_min', 'DAYS_INSTALMENT_max', 'DAYS_INSTALMENT_sum', 'DAYS_INSTALMENT_mean', 'DAYS_INSTALMENT_var', 'DAYS_INSTALMENT_std', 'NUM_INSTALMENT_VERSION_sum', 'NUM_INSTALMENT_VERSION_mean', 'NUM_INSTALMENT_VERSION_var', 'DAYS_INSTALMENT_DAYS_ENTRY_PAYMENT_DIFF_min', 'DAYS_INSTALMENT_DAYS_ENTRY_PAYMENT_DIFF_sum', 'DAYS_INSTALMENT_DAYS_ENTRY_PAYMENT_DIFF_mean', 'DAYS_INSTALMENT_DAYS_ENTRY_PAYMENT_DIFF_var', 'DAYS_INSTALMENT_DAYS_ENTRY_PAYMENT_DIFF_std', 'AMT_INSTALMENT_AMT_PAYMENT_DIFF_max', 'AMT_INSTALMENT_AMT_PAYMENT_DIFF_sum', 'AMT_INSTALMENT_AMT_PAYMENT_DIFF_mean', 'PREV_NON_CASH_TOTAL_DEBT_TO_AMT_CREDIT_min', 'PREV_NON_CASH_TOTAL_DEBT_TO_AMT_CREDIT_max', 'PREV_NON_CASH_TOTAL_DEBT_TO_AMT_CREDIT_sum', 'PREV_NON_CASH_TOTAL_DEBT_TO_AMT_CREDIT_mean', 'PREV_NON_CASH_TOTAL_DEBT_TO_AMT_CREDIT_var', 'PREV_NON_CASH_TOTAL_DEBT_TO_AMT_CREDIT_std', 'PREV_CASH_TOTAL_DEBT_TO_AMT_CREDIT_min', 'PREV_CASH_TOTAL_DEBT_TO_AMT_CREDIT_max', 'PREV_CASH_TOTAL_DEBT_TO_AMT_CREDIT_sum', 'PREV_CASH_TOTAL_DEBT_TO_AMT_CREDIT_mean', 'PREV_CASH_TOTAL_DEBT_TO_AMT_CREDIT_var', 'DAYS_DECISION_min', 'DAYS_DECISION_max', 'DAYS_DECISION_mean', 'DAYS_DECISION_var']\n",
    "print(predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "61701709863cfb4d3f5af55f676c3cba8bbc954a"
   },
   "source": [
    "**Saving Features to csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "34c3d271b75d222f5e0a6f561f4790631eee4ae4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_final.to_csv('../input/train_final.csv')\n",
    "test_final.to_csv('../input/test_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
